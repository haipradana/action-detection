{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üéØ MERL Shopping Action Recognition Training\n",
        "## Simple but Effective Approach for 5 Videos Dataset\n",
        "\n",
        "### üìã Overview:\n",
        "- **Dataset**: 5 videos, 295 clips, 5 action classes\n",
        "- **Approach**: TimeDistributed CNN + LSTM for temporal modeling\n",
        "- **Strategy**: No validation split (maximize training data)\n",
        "- **Goal**: Proof of concept with good performance\n",
        "\n",
        "### üé¨ Action Classes:\n",
        "1. **Reach To Shelf** - Reaching towards shelf\n",
        "2. **Retract From Shelf** - Moving hand back from shelf  \n",
        "3. **Hand In Shelf** - Hand inside shelf area\n",
        "4. **Inspect Product** - Looking at/examining product\n",
        "5. **Inspect Shelf** - Looking at shelf contents\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üì¶ 1. Setup and Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install tensorflow opencv-python scipy pandas numpy matplotlib scikit-learn\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    TimeDistributed, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, \n",
        "    LSTM, BatchNormalization, GlobalAveragePooling2D\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import gc\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {tf.keras.__version__}\")\n",
        "\n",
        "# GPU setup\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(f\"üî• Found {len(physical_devices)} GPU(s)\")\n",
        "for gpu in physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìä 2. Dataset Verification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify dataset structure\n",
        "print(\"üìÅ Dataset Structure Check:\")\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "print(\"\\nFolders:\")\n",
        "for folder in ['clips', 'dataframes', 'flow_clips']:\n",
        "    if os.path.exists(folder):\n",
        "        print(f\"‚úÖ {folder}/ exists\")\n",
        "    else:\n",
        "        print(f\"‚ùå {folder}/ missing\")\n",
        "\n",
        "# Check dataframes\n",
        "dataframe_files = [f for f in os.listdir('dataframes') if f.endswith('.csv')]\n",
        "print(f\"\\nüìÑ Found {len(dataframe_files)} dataframe files:\")\n",
        "for df_file in sorted(dataframe_files):\n",
        "    print(f\"   - {df_file}\")\n",
        "\n",
        "# Check clips\n",
        "clips_folders = [f for f in os.listdir('clips') if os.path.isdir(f'clips/{f}')]\n",
        "print(f\"\\nüé¨ Found {len(clips_folders)} video folders:\")\n",
        "for folder in sorted(clips_folders):\n",
        "    clip_files = len([f for f in os.listdir(f'clips/{folder}') if f.endswith('.npy')])\n",
        "    print(f\"   - {folder}: {clip_files} clips\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze class distribution\n",
        "class_distribution = [0] * 5\n",
        "total_clips = 0\n",
        "all_clip_data = []\n",
        "\n",
        "print(\"üìä Analyzing class distribution...\")\n",
        "for df_file in sorted(dataframe_files):\n",
        "    df = pd.read_csv(f'dataframes/{df_file}')\n",
        "    total_clips += len(df)\n",
        "    \n",
        "    for _, row in df.iterrows():\n",
        "        video_num = df_file.split('_')[1].split('.')[0]\n",
        "        clip_path = f\"clips/video_{video_num}/{row['name']}.npy\"\n",
        "        class_label = int(row['class']) - 1  # Convert to 0-indexed\n",
        "        \n",
        "        all_clip_data.append((clip_path, class_label))\n",
        "        class_distribution[class_label] += 1\n",
        "    \n",
        "    print(f\"   üìÑ {df_file}: {len(df)} clips\")\n",
        "\n",
        "# Action class names\n",
        "action_classes = [\n",
        "    'Reach To Shelf',\n",
        "    'Retract From Shelf', \n",
        "    'Hand In Shelf',\n",
        "    'Inspect Product',\n",
        "    'Inspect Shelf'\n",
        "]\n",
        "\n",
        "print(f\"\\nüìà Class Distribution:\")\n",
        "for i, (class_name, count) in enumerate(zip(action_classes, class_distribution)):\n",
        "    percentage = (count / total_clips * 100)\n",
        "    print(f\"   {i}: {class_name:<20} = {count:3d} clips ({percentage:5.1f}%)\")\n",
        "\n",
        "print(f\"\\nüìä Total clips: {total_clips}\")\n",
        "print(f\"üìä Balance std: {np.std([c/total_clips*100 for c in class_distribution]):.2f}%\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîÑ 3. Data Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MerlActionDataGenerator(Sequence):\n",
        "    \"\"\"\n",
        "    Simple and efficient data generator for MERL Shopping dataset\n",
        "    \"\"\"\n",
        "    def __init__(self, clip_data, sequence_length=10, batch_size=4, \n",
        "                 target_size=(224, 224), shuffle=True, augment=False):\n",
        "        self.clip_data = clip_data\n",
        "        self.sequence_length = sequence_length\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.indices = np.arange(len(self.clip_data))\n",
        "        \n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "            \n",
        "        print(f\"üìä Data Generator initialized:\")\n",
        "        print(f\"   - Total clips: {len(self.clip_data)}\")\n",
        "        print(f\"   - Sequence length: {self.sequence_length}\")\n",
        "        print(f\"   - Batch size: {self.batch_size}\")\n",
        "        print(f\"   - Batches per epoch: {len(self)}\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.clip_data) // self.batch_size\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        \n",
        "        batch_clips = []\n",
        "        batch_labels = []\n",
        "        \n",
        "        for i in batch_indices:\n",
        "            clip_path, label = self.clip_data[i]\n",
        "            \n",
        "            try:\n",
        "                # Load clip\n",
        "                clip = np.load(clip_path)\n",
        "                \n",
        "                # Adjust sequence length\n",
        "                if len(clip) >= self.sequence_length:\n",
        "                    # Take middle portion if clip is longer\n",
        "                    start_idx = (len(clip) - self.sequence_length) // 2\n",
        "                    clip = clip[start_idx:start_idx + self.sequence_length]\n",
        "                else:\n",
        "                    # Repeat frames if clip is shorter\n",
        "                    repeat_factor = self.sequence_length // len(clip) + 1\n",
        "                    clip = np.tile(clip, (repeat_factor, 1, 1, 1))[:self.sequence_length]\n",
        "                \n",
        "                # Simple augmentation\n",
        "                if self.augment and np.random.random() > 0.5:\n",
        "                    clip = np.flip(clip, axis=2)  # Horizontal flip\n",
        "                \n",
        "                batch_clips.append(clip)\n",
        "                batch_labels.append(label)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error loading {clip_path}: {e}\")\n",
        "                # Use dummy data if loading fails\n",
        "                dummy_clip = np.zeros((self.sequence_length, 224, 224, 3))\n",
        "                batch_clips.append(dummy_clip)\n",
        "                batch_labels.append(0)\n",
        "        \n",
        "        return np.array(batch_clips), np.array(batch_labels)\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data generator\n",
        "print(\"üîÑ Creating data generator...\")\n",
        "train_generator = MerlActionDataGenerator(\n",
        "    clip_data=all_clip_data,\n",
        "    sequence_length=10,  # 10 frames per sequence\n",
        "    batch_size=4,        # Small batch size for memory efficiency\n",
        "    target_size=(224, 224),\n",
        "    shuffle=True,\n",
        "    augment=True\n",
        ")\n",
        "\n",
        "# Test the generator\n",
        "print(\"\\nüß™ Testing data generator...\")\n",
        "try:\n",
        "    X_test, y_test = train_generator[0]\n",
        "    print(f\"‚úÖ Batch shape: X={X_test.shape}, y={y_test.shape}\")\n",
        "    print(f\"   X range: [{X_test.min():.3f}, {X_test.max():.3f}]\")\n",
        "    print(f\"   Labels: {y_test}\")\n",
        "    print(f\"   Unique labels: {np.unique(y_test)}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Generator test failed: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
