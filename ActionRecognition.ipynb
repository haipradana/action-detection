{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import ConvLSTM2D, Attention, Dense, Flatten, MaxPool3D, MaxPool2D,BatchNormalization\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from tensorflow.keras import Model\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = './Labels_MERL_Shopping_Dataset/'\n",
    "results_path = './Results_MERL_Shopping_Dataset/DetectedActions/'\n",
    "videos_path = './Videos_MERL_Shopping_Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_path = videos_path+'train/'\n",
    "y_train_path = 'train_y.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_path = videos_path + 'test/'\n",
    "y_test_path = 'test_y.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_path = videos_path + '/val/'\n",
    "y_val_path = 'val_y.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataGenerator(Sequence):\n",
    "    \n",
    "#     def __init__(self, x_path, y_path = None, to_fit = True,  seq_len = 30):\n",
    "#         self.x_path = x_path        \n",
    "# #         self.batch_size = batch_size\n",
    "#         self.to_fit = to_fit\n",
    "#         self.list_X = os.listdir(self.x_path)\n",
    "#         self.seq_len = seq_len\n",
    "#         if to_fit:\n",
    "#             self.y_path = y_path\n",
    "#             self.dict_Y = self.get_y(y_path)\n",
    "    \n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.list_X)\n",
    "    \n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         images_folder = self.list_X[index]\n",
    "#         images_list = sorted(os.listdir(self.x_path + images_folder))\n",
    "#         all_frames = []\n",
    "#         for img in images_list:\n",
    "#             all_frames.append(np.array(cv2.imread(x_train_path+images_folder+'/'+img)))\n",
    "        \n",
    "#         X = self.stack_frames(all_frames)\n",
    "        \n",
    "#         if self.to_fit:\n",
    "#             key = images_folder.split('_')[:2]\n",
    "#             key = '_'.join(key)\n",
    "#             Y = np.array(self.dict_Y[key])\n",
    "#             return X, Y[30:]\n",
    "        \n",
    "#         return X\n",
    "    \n",
    "#     def get_y(self, path):\n",
    "#         with open(path, 'rb') as pickle_file:\n",
    "#             y_dict = pickle.load(pickle_file)\n",
    "#         return y_dict \n",
    "    \n",
    "#     def stack_frames(self, frames):\n",
    "#         stacked_frames = []\n",
    "#         for i in range(len(frames) - self.seq_len):\n",
    "#             end = i + 30\n",
    "#             stacked_frames.append(frames[i:end])\n",
    "        \n",
    "#         return np.stack(stacked_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_generator = DataGenerator(x_train_path ,y_path = y_train_path)\n",
    "# validation_generator = DataGenerator(x_val_path ,y_path = y_val_path)\n",
    "# testing_generator = DataGenerator(x_test_path ,y_path = y_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class newGen(Sequence):\n",
    "    \n",
    "    def __init__(self, x_path, folder_name, y_path, to_fit = True, batch_size = 4, seq_len = 30):\n",
    "        self.x_path = x_path + folder_name\n",
    "        self.folder_name = folder_name\n",
    "        self.y_path = y_path\n",
    "        self.to_fit = to_fit\n",
    "        self.all_frames = self.get_all_frames(self.x_path)\n",
    "        self.targets = self.get_Y(y_path, folder_name)\n",
    "        self.series_data = TimeseriesGenerator(self.all_frames, self.targets, length = seq_len, batch_size=batch_size)\n",
    "        self.len = len(self.series_data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X, Y = self.series_data[index]\n",
    "        return tf.cast(X, tf.float16)\n",
    "    \n",
    "    def get_all_frames(self, x_path):\n",
    "        images_list = sorted(os.listdir(self.x_path))\n",
    "        all_frames = []\n",
    "        for img in images_list:\n",
    "            all_frames.append(cv2.imread(x_path+'/'+img))\n",
    "        return np.stack(all_frames)\n",
    "    \n",
    "    def get_Y(self, y_path, images_folder):\n",
    "        with open(y_path, 'rb') as pickle_file:\n",
    "            y_dict = pickle.load(pickle_file)\n",
    "        \n",
    "        key = images_folder.split('_')[:2]\n",
    "        key = '_'.join(key)\n",
    "        return np.array(y_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCL_Model(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyCL_Model, self).__init__()\n",
    "        self.convlstm_1 = ConvLSTM2D(filters=16, kernel_size=(3, 3), padding='same', return_sequences=True)\n",
    "        self.batchnorm = BatchNormalization()\n",
    "        self.maxpool3d = MaxPool3D(pool_size=(1,2,2))\n",
    "        self.maxpool2d = MaxPool2D()\n",
    "        self.convlstm_2 = ConvLSTM2D(filters=32, kernel_size=(3, 3), padding='same', return_sequences=True)\n",
    "        self.convlstm_3 = ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same', return_sequences=False)\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(10000)\n",
    "        self.dense_2 = Dense(1000)\n",
    "        self.dense_3 = Dense(100)\n",
    "        self.dense_4 = Dense(10)\n",
    "        self.classifier = Dense(1) \n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.convlstm_1(inputs)\n",
    "        x = self.batchnorm(x)\n",
    "        x = maxpool3d(x)\n",
    "        x = convlstm_2(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = maxpool3d(x)\n",
    "        x = convlstm_3(x)\n",
    "        x = maxpool2d(x)\n",
    "        x = flatten(x)\n",
    "        x = dense_1(x)\n",
    "        x = dense_2(x)\n",
    "        x = dense_3(x)\n",
    "        x = dense_4(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = MyCL_Model()\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator(generator = training_generator, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    folders = os.listdir(x_train_path)\n",
    "    for folder in folders:\n",
    "        training_generator = newGen(x_train_path, folder, y_train_path)\n",
    "        model.fit_generator(generator = training_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ip shape = (30, 680, 920, 3)\n",
    "convlstm return sequences true 5d else 4d\n",
    "batchnorm\n",
    "maxpool3d\n",
    "\n",
    "attention\n",
    "then flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(testing_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
